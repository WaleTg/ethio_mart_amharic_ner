from typing import List


class Tokenize(object):
    def __init__(self) -> None:
        pass
    
    def word_tokenize(sef, text) -> List[str]:
        pass
    
    def sent_tokenize(sef, text) -> List[str]:
        pass

    def _whitespace_tokenizer(self, text) -> List[str]:
        pass